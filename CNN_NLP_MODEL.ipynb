{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Dropout, Activation,concatenate, Input\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING THE CLEANED DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_title = pd.read_pickle(r\"D:\\Poonam\\Project\\clean_x_train_title.pkl\")\n",
    "x_test_title = pd.read_pickle(r\"D:\\Poonam\\Project\\clean_x_test_title.pkl\")\n",
    "\n",
    "x_train_body = pd.read_pickle(r\"D:\\Poonam\\Project\\clean_x_train_body.pkl\")\n",
    "x_test_body = pd.read_pickle(r\"D:\\Poonam\\Project\\clean_x_test_body.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((565068,), (141268,), (565068,), (141268,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_title.shape , x_test_title.shape, x_train_body.shape , x_test_body.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_pickle(r\"D:\\Poonam\\Project\\y_train.pkl\")\n",
    "y_test = pd.read_pickle(r\"D:\\Poonam\\Project\\y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((565068,), (141268,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATRIX OF TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_len=[]\n",
    "\n",
    "for title in x_train_title:\n",
    "    title_len.append(len(word_tokenize(title)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(title_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.quantile(title_len,0.95))\n",
    "np.quantile(title_len,0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_len1=[]\n",
    "for title in x_test_title:\n",
    "    title_len1.append(len(word_tokenize(title)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "9.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(max(title_len1))\n",
    "print(np.quantile(title_len1,0.95))\n",
    "np.quantile(title_len1,0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len1=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer(char_level=False, split=' ')\n",
    "tok.fit_on_texts(x_train_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101026"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len1=len(tok.index_word.keys())\n",
    "vocab_len1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565068, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_train_title = tok.texts_to_sequences(x_train_title)\n",
    "seq_train_title\n",
    "\n",
    "matrix_train_title = sequence.pad_sequences(seq_train_title, maxlen=max_len1)\n",
    "matrix_train_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141268, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_test_title = tok.texts_to_sequences(x_test_title)\n",
    "seq_test_title\n",
    "\n",
    "matrix_test_title = sequence.pad_sequences(seq_test_title, maxlen=max_len1)\n",
    "matrix_test_title.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATRIX FOR BODY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_len=[]\n",
    "\n",
    "for body in x_train_body:\n",
    "    body_len.append(len(word_tokenize(body)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315.0\n"
     ]
    }
   ],
   "source": [
    "max(body_len)\n",
    "\n",
    "print(np.quantile(body_len,0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_len1=[]\n",
    "for body in x_test_body:\n",
    "    body_len1.append(len(word_tokenize(body)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8445\n",
      "313.0\n"
     ]
    }
   ],
   "source": [
    "print(max(body_len1))\n",
    "print(np.quantile(body_len1,0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len2=330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3945147"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.fit_on_texts(x_train_body)\n",
    "\n",
    "vocab_len2=len(tok.index_word.keys())\n",
    "vocab_len2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565068, 330)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_train_body = tok.texts_to_sequences(x_train_body)\n",
    "seq_train_body\n",
    "\n",
    "matrix_train_body = sequence.pad_sequences(seq_train_body, maxlen=max_len2)\n",
    "matrix_train_body.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141268, 330)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_test_body = tok.texts_to_sequences(x_test_body)\n",
    "seq_test_body\n",
    "\n",
    "matrix_test_body = sequence.pad_sequences(seq_test_body, maxlen=max_len2)\n",
    "matrix_test_body.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565068, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "train_y = mlb.fit_transform(y_train)\n",
    "\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title_input (InputLayer)        (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "body_input (InputLayer)         (None, 330)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 100)      10102700    title_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 330, 100)     394514800   body_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 19, 32)       6432        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 329, 32)      6432        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 19, 32)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 329, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 9, 32)        0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 164, 32)      0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 288)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 5248)         0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 288)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 5248)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          28900       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          524900      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 50)           10050       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 50)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 10)           510         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 405,194,724\n",
      "Trainable params: 405,194,724\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def multiclass_model():\n",
    "    # channel 1 for title\n",
    "    input1 = Input( shape=(max_len1,),name = \"title_input\")\n",
    "    embed1 = Embedding(vocab_len1+1,100)(input1)\n",
    "    conv1 = Conv1D(filters=32, kernel_size = 2, activation=\"relu\")(embed1)\n",
    "    drop1 = Dropout(0.2)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    drop2 = Dropout(0.2)(flat1)\n",
    "    dense1 = Dense(100, activation=\"relu\")(drop2)\n",
    "    \n",
    "    #channel 2 for body\n",
    "    input2 = Input( shape=(max_len2,),name = \"body_input\")\n",
    "    embed2 = Embedding(vocab_len2+1,100)(input2)\n",
    "    conv2 = Conv1D(filters=32, kernel_size = 2, activation=\"relu\")(embed2)\n",
    "    drop3 = Dropout(0.2)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    drop4 = Dropout(0.2)(flat2)\n",
    "    dense2 = Dense(100 ,activation=\"relu\")(drop4)\n",
    "    \n",
    "    merged = concatenate([dense1,dense2])\n",
    "    \n",
    "    dense3 = Dense(50, activation=\"relu\")(merged)\n",
    "    drop5 = Dropout(0.2)(dense3)\n",
    "    \n",
    "    # output layer\n",
    "    \n",
    "    output = Dense(10,name =\"main_output\", activation=\"sigmoid\")(drop5)\n",
    "    \n",
    "    model = Model(inputs=[input1,input2],outputs=output)\n",
    "    return model\n",
    "\n",
    "model = multiclass_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINING CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau, EarlyStopping\n",
    "import os\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "filepath = r'D:\\Poonam\\Project\\Stack_m2_output.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=True, \n",
    "                             mode='auto')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', \n",
    "                          min_delta=0.01, patience= 5,\n",
    "                          verbose=1, mode='auto')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 565068 samples, validate on 141268 samples\n",
      "Epoch 1/30\n",
      "565068/565068 [==============================] - 899s 2ms/step - loss: 2.5716 - accuracy: 0.1710 - val_loss: 2.2709 - val_accuracy: 0.2630\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.26300, saving model to D:\\Poonam\\Project\\Stack_m2_output.h5\n",
      "Epoch 2/30\n",
      "565068/565068 [==============================] - 1095s 2ms/step - loss: 1.9699 - accuracy: 0.3277 - val_loss: 1.6228 - val_accuracy: 0.5131\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.26300 to 0.51315, saving model to D:\\Poonam\\Project\\Stack_m2_output.h5\n",
      "Epoch 3/30\n",
      "565068/565068 [==============================] - 1125s 2ms/step - loss: 1.4665 - accuracy: 0.5532 - val_loss: 1.2372 - val_accuracy: 0.6797\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.51315 to 0.67973, saving model to D:\\Poonam\\Project\\Stack_m2_output.h5\n",
      "Epoch 4/30\n",
      "565068/565068 [==============================] - 1113s 2ms/step - loss: 1.1202 - accuracy: 0.7018 - val_loss: 1.0369 - val_accuracy: 0.7350\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67973 to 0.73504, saving model to D:\\Poonam\\Project\\Stack_m2_output.h5\n",
      "Epoch 5/30\n",
      "565068/565068 [==============================] - 1082s 2ms/step - loss: 0.9078 - accuracy: 0.7776 - val_loss: 0.9417 - val_accuracy: 0.7725\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.73504 to 0.77252, saving model to D:\\Poonam\\Project\\Stack_m2_output.h5\n",
      "Epoch 6/30\n",
      "565068/565068 [==============================] - 1096s 2ms/step - loss: 0.7762 - accuracy: 0.8214 - val_loss: 0.8944 - val_accuracy: 0.7919\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.77252 to 0.79193, saving model to D:\\Poonam\\Project\\Stack_m2_output.h5\n",
      "Epoch 7/30\n",
      "565068/565068 [==============================] - 1106s 2ms/step - loss: 0.6881 - accuracy: 0.8464 - val_loss: 0.8808 - val_accuracy: 0.7988\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.79193 to 0.79884, saving model to D:\\Poonam\\Project\\Stack_m2_output.h5\n",
      "Epoch 8/30\n",
      "565068/565068 [==============================] - 1110s 2ms/step - loss: 0.6214 - accuracy: 0.8621 - val_loss: 0.8767 - val_accuracy: 0.8005\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.79884 to 0.80046, saving model to D:\\Poonam\\Project\\Stack_m2_output.h5\n",
      "Epoch 9/30\n",
      "565068/565068 [==============================] - 1107s 2ms/step - loss: 0.5691 - accuracy: 0.8732 - val_loss: 0.8807 - val_accuracy: 0.7996\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80046\n",
      "Epoch 10/30\n",
      "565068/565068 [==============================] - 1097s 2ms/step - loss: 0.5297 - accuracy: 0.8798 - val_loss: 0.8892 - val_accuracy: 0.7965\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80046\n",
      "Epoch 11/30\n",
      "565068/565068 [==============================] - 1104s 2ms/step - loss: 0.4980 - accuracy: 0.8848 - val_loss: 0.9030 - val_accuracy: 0.7975\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.80046\n",
      "Epoch 12/30\n",
      "565068/565068 [==============================] - 1184s 2ms/step - loss: 0.4729 - accuracy: 0.8886 - val_loss: 0.9120 - val_accuracy: 0.7976\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.80046\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "results=model.fit({'title_input': matrix_train_title, 'body_input': matrix_train_body}, train_y,\n",
    "          validation_data = [{'title_input':matrix_test_title, 'body_input': matrix_test_body},test_y], epochs=30, batch_size=20000, callbacks=[checkpoint,earlystop,reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVING THE MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "model_json = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Stack_m2.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
